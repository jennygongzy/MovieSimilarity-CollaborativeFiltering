{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**This project is to find the similar movies for each of the target movie using Item-based Collaborative Filtering.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Set-up and Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc.stop()\n",
    "from pyspark import SparkContext \n",
    "sc = SparkContext('local','pyspark')\n",
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie- Count by Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'196\\t242\\t3\\t881250949',\n",
       " u'186\\t302\\t3\\t891717742',\n",
       " u'22\\t377\\t1\\t878887116',\n",
       " u'244\\t51\\t2\\t880606923',\n",
       " u'166\\t346\\t1\\t886397596']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesrdd = sc.textFile('file://' + cwd + '/ml-100k/u.data')\n",
    "moviesrdd.take(5)\n",
    "#user_id  item_id  rating  timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'1': 6110, u'2': 11370, u'3': 27145, u'4': 34174, u'5': 21201}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_counter = (moviesrdd\n",
    " .map(lambda x:x.split('\\t')[2])\n",
    " .map(lambda x:(x,1))  \n",
    " .reduceByKey(lambda x,y:x+y)\n",
    " .sortByKey()\n",
    " .collectAsMap()\n",
    ")\n",
    "ratings_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Most Popular Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'196\\t242\\t3\\t881250949',\n",
       " u'186\\t302\\t3\\t891717742',\n",
       " u'22\\t377\\t1\\t878887116',\n",
       " u'244\\t51\\t2\\t880606923',\n",
       " u'166\\t346\\t1\\t886397596']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesrdd = sc.textFile('file://' + cwd + '/ml-100k/u.data')\n",
    "moviesrdd.take(5)\n",
    "#user_id  item_id  rating  timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'50', 583),\n",
       " (u'258', 509),\n",
       " (u'100', 508),\n",
       " (u'181', 507),\n",
       " (u'294', 485),\n",
       " (u'286', 481),\n",
       " (u'288', 478),\n",
       " (u'1', 452),\n",
       " (u'300', 431),\n",
       " (u'121', 429)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MostPopularMovie = (moviesrdd\n",
    "                    .map(lambda x:x.split('\\t')[1])\n",
    "                    .map(lambda x:(x,1))\n",
    "                    .reduceByKey(lambda x,y:x+y) #counting\n",
    "                    .sortBy(lambda (id,count):count, ascending = False)\n",
    "                    .take(10)\n",
    "                    )\n",
    "MostPopularMovie\n",
    "#movie_id, count                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map movie_id with the actural movie name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Star Wars (1977)', 583),\n",
       " ('Contact (1997)', 509),\n",
       " ('Fargo (1996)', 508),\n",
       " ('Return of the Jedi (1983)', 507),\n",
       " ('Liar Liar (1997)', 485),\n",
       " ('English Patient, The (1996)', 481),\n",
       " ('Scream (1996)', 478),\n",
       " ('Toy Story (1995)', 452),\n",
       " ('Air Force One (1997)', 431),\n",
       " ('Independence Day (ID4) (1996)', 429)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"ml-100k/u.ITEM\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames # {id:name}\n",
    "\n",
    "## broadcast the dictionary to every node in cluster, efficient! \n",
    "nameDict = sc.broadcast(loadMovieNames())\n",
    "\n",
    "result = (moviesrdd\n",
    "          .map(lambda x:x.split('\\t')[1])\n",
    "          .map(lambda x:(int(x),1))\n",
    "          .reduceByKey(lambda x,y:x+y) #counting\n",
    "          .sortBy(lambda (id,count):count, ascending = False)\n",
    "          .map(lambda (id,count):(nameDict.value[id],count))   ## retrieve dictionary value using .value\n",
    "          .take(10)\n",
    "          )\n",
    "result\n",
    "#name, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Popular Marvel Hero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = sc.textFile('file://'+cwd+'/marvel-names.txt')\n",
    "namesRdd = names.map(lambda x:(int(x.split('\\\"')[0]),x.split('\\\"')[1].encode(\"utf8\"))).collectAsMap()\n",
    "nameDict = sc.broadcast(namesRdd)\n",
    "#{hero_id,hero_name}\n",
    "\n",
    "graph = sc.textFile('file://'+cwd+'/marvel-graph.txt')\n",
    "graphRdd = graph.map(lambda x:(int(x.split()[0]),len(x.split())-1))\n",
    "#hero_id,count_of_coccurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CAPTAIN AMERICA', 1933),\n",
       " ('SPIDER-MAN/PETER PAR', 1741),\n",
       " ('IRON MAN/TONY STARK ', 1528),\n",
       " ('THING/BENJAMIN J. GR', 1426),\n",
       " ('WOLVERINE/LOGAN ', 1394),\n",
       " ('MR. FANTASTIC/REED R', 1386),\n",
       " ('HUMAN TORCH/JOHNNY S', 1371),\n",
       " ('SCARLET WITCH/WANDA ', 1345),\n",
       " ('THOR/DR. DONALD BLAK', 1289),\n",
       " ('BEAST/HENRY &HANK& P', 1280)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MostPopularHero = (graphRdd\n",
    "                   .reduceByKey(lambda x,y:x+y)\n",
    "                   .sortBy(lambda (id,count):count,ascending = False)\n",
    "                   .map(lambda (id,count):(nameDict.value[id],count)) #Map Hero id with name \n",
    "                   .take(10)\n",
    "                   )\n",
    "MostPopularHero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering (Item-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\") #need to use all the cores\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "data = sc.textFile(\"file://\"+cwd+\"/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"ml-100k/u.ITEM\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1].decode('ascii', 'ignore')\n",
    "    return movieNames\n",
    "\n",
    "nameDict = sc.broadcast(loadMovieNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "# Self-join to find every combination.\n",
    "## Very expensive!!\n",
    "joinedRatings = ratings.join(ratings)\n",
    "\n",
    "# Now: \n",
    "#(userID,((movieID, rating), (movieID, rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterDuplicates( (userID, ratings) ):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2\n",
    "\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePairs((user, ratings)):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
    "\n",
    "#Now: \n",
    "#(movie1,movie2):(rating1,rating2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePairRatings = moviePairs.groupByKey()\n",
    "#(movie1, movie2):(rating1, rating2), (rating1, rating2) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n",
    "moviePairSimilarities.sortByKey()\n",
    "moviePairSimilarities.saveAsTextFile(\"movie-sims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract similar movies for one paticular movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieID = 50   # \"Star Wars (1977)\"\n",
    "scoreThreshold = 0.97\n",
    "coOccurenceThreshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies for Star Wars (1977)\n",
      "Empire Strikes Back, The (1980)\tscore: 0.989552207839\tstrength: 345\n",
      "Return of the Jedi (1983)\tscore: 0.985723086125\tstrength: 480\n",
      "Raiders of the Lost Ark (1981)\tscore: 0.981760098873\tstrength: 380\n",
      "20,000 Leagues Under the Sea (1954)\tscore: 0.97893856055\tstrength: 68\n",
      "12 Angry Men (1957)\tscore: 0.977657612045\tstrength: 109\n",
      "Close Shave, A (1995)\tscore: 0.977594829105\tstrength: 92\n",
      "African Queen, The (1951)\tscore: 0.976469222267\tstrength: 138\n",
      "Sting, The (1973)\tscore: 0.975151293774\tstrength: 204\n",
      "Wrong Trousers, The (1993)\tscore: 0.974868135546\tstrength: 103\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996)\tscore: 0.97418161283\tstrength: 58\n"
     ]
    }
   ],
   "source": [
    "#Filter on the above threshold\n",
    "filteredResults = moviePairSimilarities.filter(lambda((pair,sim)): \\\n",
    "    (pair[0] == movieID or pair[1] == movieID) \\\n",
    "    and sim[0] > scoreThreshold and sim[1] > coOccurenceThreshold)\n",
    "\n",
    "#Sort by quality score\n",
    "results = filteredResults.map(lambda((pair,sim)): (sim, pair)).sortByKey(ascending = False).take(10)\n",
    "\n",
    "print(\"Top 10 similar movies for \" + nameDict.value[movieID])\n",
    "for result in results:\n",
    "    (sim, pair) = result\n",
    "    #Display only the similarity result that isn't the movie we're looking at\n",
    "    similarMovieID = pair[0]\n",
    "    if (similarMovieID == movieID):\n",
    "        similarMovieID = pair[1]\n",
    "    print(nameDict.value[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
